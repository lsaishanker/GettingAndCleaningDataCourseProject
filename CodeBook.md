
## The CodeBook.md describes the data fields in tidy_data_set.txt file generated by the R script run_analysis.R.
### The data in tidy_data_set.txt can be categorized as:-

#### Subject - This is an Identifier of the subject who was involved in the experiment to generate the readings/features.

#### Activity - Activity describes all the kinds of activities that the subject had performed to generate the readings.
                The following are the Activity labels:-
				* WALKING
				* WALKING_UPSTAIRS
				* WALKING_DOWNSTAIRS
				* SITTING
				* STANDING
				* LAYING

#### Features - All the remaining columns can be categorized under types of features. The values are averages of mean and standard deviation of the readings respectively.
				
### Brief description about the dataset.

	Human Activity Recognition Using Smartphones Dataset
	Version 1.0

	Jorge L. Reyes-Ortiz, Davide Anguita, Alessandro Ghio, Luca Oneto.
	Smartlab - Non Linear Complex Systems Laboratory
	DITEN - Università degli Studi di Genova.
	Via Opera Pia 11A, I-16145, Genoa, Italy.
	activityrecognition@smartlab.ws
   [LinkToSmartLab](www.smartlab.ws)


	The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. 
	Each person performed six activities 
	(WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) 
	wearing a smartphone (Samsung Galaxy S II) on the waist. 
	Using its embedded accelerometer and gyroscope, 
	we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz.	


	The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and 
	then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). 
	The sensor acceleration signal, which has gravitational and body motion components, 
	was separated using a Butterworth low-pass filter into body acceleration and gravity.
	The gravitational force is assumed to have only low frequency components, 
	therefore a filter with 0.3 Hz cutoff frequency was used. 
	From each window, a vector of features was obtained by calculating variables from the time and frequency domain.

### A full description is available at the site below about where the input data set used in this project was obtained:

  [LinkToInformationAboutInputDataSet](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)